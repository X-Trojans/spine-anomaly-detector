{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c45054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd, random\n",
    "import torch, torch.nn as nn\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.optim import SGD, AdamW\n",
    "from torch.utils import data\n",
    "from torchvision import transforms, models\n",
    "from pydicom import read_file\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "from sklearn.metrics import classification_report\n",
    "import multiprocessing\n",
    "import pytorch_lightning as pl\n",
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "from pl_bolts.models.self_supervised.simclr.transforms import (\n",
    "    SimCLREvalDataTransform, SimCLRTrainDataTransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ead19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea19822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd0db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/scratch1/knarasim/physionet.org/files/vindr-spinexr/1.0.0/'\n",
    "train_path = path + \"train_images/\"\n",
    "test_path  = path + \"test_images/\"\n",
    "annot_path = path + \"annotations/\"\n",
    "tiny_path = \"/\".join(path.split(\"/\")[:-2]) + \"/tiny_vindr/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b5bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(tiny_path, exist_ok=True)\n",
    "os.makedirs(tiny_path + \"train_images/\", exist_ok=True)\n",
    "os.makedirs(tiny_path + \"test_images/\", exist_ok=True)\n",
    "os.makedirs(tiny_path + \"annotations/\", exist_ok=True)\n",
    "\n",
    "def read_xray(path, voi_lut=True, fix_monochrome=True):\n",
    "    \n",
    "    dicom = read_file(path)\n",
    "    # transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut and len(dicom.get(\"VOILUTSequence\", [])):\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array.astype(\"float\")\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        data = np.amax(data) - data\n",
    "    data -= np.min(data)\n",
    "    data /= np.max(data)\n",
    "    data *= 255\n",
    "        \n",
    "    return data.astype(np.uint8)\n",
    "\n",
    "def save_tiny_dicom_train(dicom_file):\n",
    "    name = dicom_file.split(\".\")[0]\n",
    "    if not dicom_file.endswith(\"dicom\"):\n",
    "        return\n",
    "    a = read_xray(train_path + dicom_file)\n",
    "    plt.imsave(tiny_path + f\"train_images/{name}.jpg\", a)\n",
    "    \n",
    "def save_tiny_dicom_test(dicom_file):\n",
    "    name = dicom_file.split(\".\")[0]\n",
    "    if not dicom_file.endswith(\"dicom\"):\n",
    "        return\n",
    "    a = read_xray(test_path + dicom_file)\n",
    "    plt.imsave(tiny_path + f\"test_images/{name}.jpg\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73af0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Make Tiny Version\n",
    "annotations = pd.read_csv(annot_path + \"train.csv\")\n",
    "annotations = annotations[[\"image_id\", \"lesion_type\", \"xmin\", \"ymin\", \"xmax\", \"ymax\"]]\n",
    "annotations.to_csv(tiny_path + \"annotations/train.csv\")\n",
    "\n",
    "pool_obj = multiprocessing.Pool(200)\n",
    "train_dicom_files = os.listdir(train_path)\n",
    "_ = pool_obj.map(save_tiny_dicom_train,train_dicom_files)\n",
    "pool_obj.close()\n",
    "\n",
    "annotations = pd.read_csv(annot_path + \"test.csv\")\n",
    "annotations = annotations[[\"image_id\", \"lesion_type\", \"xmin\", \"ymin\", \"xmax\", \"ymax\"]]\n",
    "annotations.to_csv(tiny_path + \"annotations/test.csv\")\n",
    "\n",
    "pool_obj = multiprocessing.Pool(200)\n",
    "test_dicom_files = os.listdir(test_path)\n",
    "_ = pool_obj.map(save_tiny_dicom_test,test_dicom_files)\n",
    "pool_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf771d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(path):\n",
    "    train_path = path + \"train_images/\"\n",
    "    train_list = [os.path.join(train_path, img) for img in os.listdir(train_path)]\n",
    "    random.shuffle(train_list)\n",
    "    threshold = int(0.8 * len(train_list))\n",
    "    valid_list = train_list[threshold:]\n",
    "    train_list = train_list[:threshold]\n",
    "    test_path = path + \"test_images/\"\n",
    "    test_list = [os.path.join(test_path, img) for img in os.listdir(test_path)]\n",
    "    return train_list, valid_list, test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2753ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/scratch1/knarasim/physionet.org/files/vindr-spinexr/tiny_vindr/'\n",
    "train, valid, test = train_test_split(path)\n",
    "annotations = pd.read_csv(annot_path + \"train.csv\")\n",
    "train_annot = [\n",
    "    annotations.iloc[idx] for idx, row in enumerate(annotations.iterrows()) \\\n",
    "        if \"{}train_images/{}.jpg\".format(path, row[1][\"image_id\"]) in train\n",
    "]\n",
    "train_annot = pd.DataFrame(train_annot).drop_duplicates(subset=[\"image_id\"]).sort_values(by=[\"image_id\"])\n",
    "valid_annot = [\n",
    "    annotations.iloc[idx] for idx, row in enumerate(annotations.iterrows()) \\\n",
    "        if \"{}train_images/{}.jpg\".format(path, row[1][\"image_id\"]) in valid\n",
    "]\n",
    "valid_annot = pd.DataFrame(valid_annot).drop_duplicates(subset=[\"image_id\"]).sort_values(by=[\"image_id\"])\n",
    "annotations = pd.read_csv(annot_path + \"test.csv\")\n",
    "test_annot = [\n",
    "    annotations.iloc[idx] for idx, row in enumerate(annotations.iterrows()) \\\n",
    "        if \"{}test_images/{}.jpg\".format(path, row[1][\"image_id\"]) in test\n",
    "]\n",
    "test_annot = pd.DataFrame(test_annot).drop_duplicates(subset=[\"image_id\"]).sort_values(by=[\"image_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e100e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VinDrSpineXR(data.Dataset):\n",
    "    def __init__(self, root_dir, annot_df, transform=None):\n",
    "        self.img_paths = root_dir\n",
    "        self.img_paths.sort()\n",
    "        self.transform = transform\n",
    "        self.labels = annot_df[[\"image_id\", \"lesion_type\"]]\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.img_paths[idx])\n",
    "        #  0: Abnormal  |  1: Normal\n",
    "        label = self.labels.iloc[idx, 1] == \"No finding\"\n",
    "        image = self.transform(image)\n",
    "        return image, label*1\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7f3a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = VinDrSpineXR(train, train_annot, train_transform)\n",
    "valid_dataset = VinDrSpineXR(valid, valid_annot, train_transform)\n",
    "test_dataset  = VinDrSpineXR(test , test_annot , test_transform )\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = data.DataLoader(test_dataset , batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d55f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Build and Train Network Model\n",
    "class XRModel(nn.Module):\n",
    "    def __init__(self, n_classes, use_pretrained=True, freeze=True):\n",
    "        super(XRModel, self).__init__()\n",
    "        self.base_net = models.densenet169(pretrained=use_pretrained)\n",
    "        if freeze:\n",
    "            for child in self.base_net.children():\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "        n_feats = self.base_net.classifier.in_features\n",
    "        self.base_net.classifier = nn.Linear(n_feats, 256)\n",
    "        self.cls = nn.Sequential(nn.LeakyReLU(), nn.Linear(256, n_classes))\n",
    "    def forward(self, input):\n",
    "        return self.cls(self.base_net(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4394925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = XRModel(n_classes=2, freeze=False).to(device)\n",
    "optim = AdamW(model.parameters(), lr=1e-3)\n",
    "lossf = nn.CrossEntropyLoss()\n",
    "n_epochs = 1 #38 + 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d0f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, n_epochs+1):\n",
    "    print(f\"\\nEpoch {i}:\")\n",
    "    print(\"-\"*10)\n",
    "    running_loss, running_hits = 0.0, 0.0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optim.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            out = model(images)\n",
    "            loss = lossf(out, labels)\n",
    "            _, pred = torch.max(out, 1)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "    \n",
    "        running_loss += loss.item()\n",
    "        #running_hits += torch.true_divide(torch.sum(pred == labels),len(labels))\n",
    "        running_hits += (torch.sum(pred == labels)).item() / batch_size\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc  = running_hits / len(train_loader)\n",
    "    print(\"Train Loss: {:.3f}\\t Acc: {:.3f}\".format(epoch_loss, epoch_acc))\n",
    "    \n",
    "    running_loss, running_hits = 0.0, 0.0\n",
    "    for images, labels in tqdm(valid_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            out = model(images)\n",
    "            loss = lossf(out, labels)\n",
    "            _, pred = torch.max(out, 1)\n",
    "    \n",
    "        running_loss += loss.item()\n",
    "        #running_hits += torch.true_divide(torch.sum(pred == labels),len(labels))\n",
    "        running_hits += (torch.sum(pred == labels)).item() / batch_size\n",
    "        \n",
    "    epoch_loss = running_loss / len(valid_loader)\n",
    "    epoch_acc  = running_hits / len(valid_loader)\n",
    "    print(\"Valid Loss: {:.3f}\\t Acc: {:.3f}\".format(epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697fe0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, path + \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138958fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, trues = [], []\n",
    "with torch.set_grad_enabled(False):\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out = model(images)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        predictions.append(pred)\n",
    "        trues.append(labels)\n",
    "        \n",
    "predictions = torch.cat(predictions).detach().cpu().numpy()\n",
    "trues = torch.cat(trues).detach().cpu().numpy()\n",
    "print(classification_report(trues, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
